{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Layer-wise Relevance Propagation (LRP) for sentiment analysis for English Language. The package used to implement LRP is innvestigate. The dataset used is Large Movie Review Dataset (Imdb reviews). The distribution of positive and negative reviews in training and test dataset is also equal (12.5K pos and 12.5 neg reviews in each training and test dataset). The model in use is feed forwards neural network with three dense hidden layers using Keras. The vectorization technique used for text is GloVe word embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset location: https://ai.stanford.edu/~amaas/data/sentiment/ and extract the folder in the current directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LRP paper: http://iphome.hhi.de/samek/pdf/MonXAI19.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe word embedding: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation reference: https://github.com/albermax/innvestigate/blob/master/examples/notebooks/sentiment_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "import innvestigate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data import</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_folder(name):\n",
    "    data = []\n",
    "    for verdict in ('neg', 'pos'):\n",
    "        for file in glob(os.path.join(name, verdict, '*.txt')):\n",
    "            data.append({\n",
    "                'text': open(file, encoding='utf8').read(),\n",
    "                'verdict': verdict == 'pos'\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_train = parse_folder('../aclImdb/train/')\n",
    "df_test = parse_folder('../aclImdb/test/')\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16064</td>\n",
       "      <td>Let me be up-front, I like pulp. However it is...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36542</td>\n",
       "      <td>Having enjoyed Koyaanisqatsi and Powaqatsi I w...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48042</td>\n",
       "      <td>The beautiful, charming, supremely versatile a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3993</td>\n",
       "      <td>To me this just comes off as a soap opera. I g...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38507</td>\n",
       "      <td>This is truly a funny movie. His dance scene d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  verdict\n",
       "16064  Let me be up-front, I like pulp. However it is...     True\n",
       "36542  Having enjoyed Koyaanisqatsi and Powaqatsi I w...    False\n",
       "48042  The beautiful, charming, supremely versatile a...     True\n",
       "3993   To me this just comes off as a soap opera. I g...    False\n",
       "38507  This is truly a funny movie. His dance scene d...     True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Basic text preprocessing</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "X_text = []\n",
    "sentences = list(df['text'])\n",
    "for sen in sentences:\n",
    "    X_text.append(preprocess_text(sen))\n",
    "    \n",
    "y = df['verdict']\n",
    "y = np.array(list(map(lambda x: 0 if x==True else 1, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Text tokenizing & padding</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_text)\n",
    "X_tokenized = tokenizer.texts_to_sequences(X_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 200\n",
    "X_padded_tokens = pad_sequences(X_tokenized, padding='post', truncating='post',maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Word embedding</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Embedded dataset preparation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_embedding = np.zeros((100,))\n",
    "embedded_X_train = np.zeros((len(X_padded_tokens), 200, 100))\n",
    "for i, row in enumerate(X_padded_tokens):\n",
    "    for j, token_number in enumerate(row):\n",
    "        try:\n",
    "            token_word = tokenizer.index_word[token_number]\n",
    "            token_embedding = embeddings_dictionary[token_word]\n",
    "            embedded_X_train[i,j,:] = token_embedding\n",
    "        except:\n",
    "            embedded_X_train[i,j,:] = zero_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Keras 3 hidden layer model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Rohan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "flatten_layer = Flatten()\n",
    "model.add(flatten_layer)\n",
    "dense_layer_one = Dense(256, activation='relu')\n",
    "model.add(dense_layer_one)\n",
    "dense_layer_two = Dense(256, activation='relu')\n",
    "model.add(dense_layer_two)\n",
    "dense_layer_three = Dense(256, activation='relu')\n",
    "model.add(dense_layer_three)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "model.add(output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Model training</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Rohan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/6\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.6154 - acc: 0.6760\n",
      "Epoch 2/6\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.4698 - acc: 0.7753\n",
      "Epoch 3/6\n",
      "50000/50000 [==============================] - 84s 2ms/step - loss: 0.4011 - acc: 0.8163\n",
      "Epoch 4/6\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.3437 - acc: 0.8441\n",
      "Epoch 5/6\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.2665 - acc: 0.8808\n",
      "Epoch 6/6\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.2010 - acc: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3137ec490>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(embedded_X_train, y , epochs=6, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>5 random cases for XAI</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24338, 15011, 22339, 12563, 19677]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cases = list(np.random.random_integers(0,49999,size=[5,]))\n",
    "random_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initiating LRP instance</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "innvestigate_method = 'lrp.z'\n",
    "analyzer = innvestigate.create_analyzer(innvestigate_method, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>XAI preparation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top(case_no):\n",
    "    case = embedded_X_train[case_no].reshape(1,200,100)\n",
    "    \n",
    "    if y[case_no] == 0:\n",
    "        cla = 'Positive review'\n",
    "    else:\n",
    "        cla = 'Negative review'\n",
    "    print(\"True class:\", cla)\n",
    "    \n",
    "    pred = model.predict(case)\n",
    "    if pred < 0.5:\n",
    "        cla = 'Positive review'\n",
    "    else:\n",
    "        cla = 'Negative review'\n",
    "    print(\"Predicted class:\", cla, '(',pred[0][0],')','[0=True, 1=False]')\n",
    "    \n",
    "    scores = np.sum(np.squeeze(analyzer.analyze(case)), axis=1)\n",
    "    \n",
    "    print(\"\\nTop 10 - Positive Contribute\")\n",
    "    top_set = []\n",
    "    for i, tk in enumerate(X_padded_tokens[case_no][scores.argsort()[-5:][::-1]]):\n",
    "        try:\n",
    "            top_set.append((tokenizer.index_word[tk], scores[scores.argsort()[-5:][::-1]][i]))\n",
    "        except:\n",
    "            1\n",
    "    print(top_set)\n",
    "    \n",
    "    print(\"\\nTop 10 - Negative Contribute\")\n",
    "    bottom_set = []\n",
    "    for i, tk in enumerate(X_padded_tokens[case_no][np.flip(scores.argsort()[:5][::-1])]):\n",
    "        try:\n",
    "            bottom_set.append((tokenizer.index_word[tk], scores[scores.argsort()[:5][::-1]][i]))\n",
    "        except:\n",
    "            1\n",
    "    print(bottom_set)\n",
    "    \n",
    "    print(\"\\nText:\\n\", X_text[case_no])\n",
    "    print(\"\\n----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>XAI</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class: Negative review\n",
      "Predicted class: Negative review ( 0.9515501 ) [0=True, 1=False]\n",
      "\n",
      "Top 10 - Positive Contribute\n",
      "[('ed', 0.23428376), ('running', 0.19387451), ('believe', 0.1913349), ('not', 0.18128063), ('plot', 0.16896152)]\n",
      "\n",
      "Top 10 - Negative Contribute\n",
      "[('him', -0.1360347), ('film', -0.14448667), ('who', -0.16167434), ('introduces', -0.17170446), ('ray', -0.19200623)]\n",
      "\n",
      "Text:\n",
      " I was ed when couldn see this one when it was screening at the Philly Film Fest last year so when saw that it was going to be on cable tonight put it on remind as soon as could So was it worth the wait Well let backtrack tad as have yet to give you the plot Sean Crawley is young man who doesn know what his path in life is Enter Duke George Wendt who introduces him to his boss Ray Danny Baldwin One night Ray totally hammered asks Sean to off the guy that they had Sean following around And it goes on from there Which leads me back to the question posed Was it worth the wait Yes and no the buildup was pretty good and George Wendt stole the movie for me He just took the ball and ran with it But it nowhere near as violent as was led to believe and somewhere along the movies running time the ball is not only dropped but fumbled and taken in the other direction know where this point happened exactly but can say without spoiling the film But needless to say it happened The ending doesn save the film either Poor Stuart Gordon nothing can be good like Re animator or Castle Freak My Grade CWhere saw it Showtime ExtremeEye Candy Kari Wuhrer shows her ta tas in one fantasy and then in the next more ta tas and it pans down and OH MY GOD MY EYES MY EYES \n",
      "\n",
      "----------------------------------------------\n",
      "True class: Positive review\n",
      "Predicted class: Positive review ( 0.17550802 ) [0=True, 1=False]\n",
      "\n",
      "Top 10 - Positive Contribute\n",
      "[('music', 0.049079034), ('see', 0.04285609), ('think', 0.038557213), ('very', 0.036675572), ('all', 0.03317849)]\n",
      "\n",
      "Top 10 - Negative Contribute\n",
      "[('to', -0.036320645), ('budget', -0.037741102), ('project', -0.038447063), ('of', -0.04832669), ('of', -0.055086017)]\n",
      "\n",
      "Text:\n",
      " Everyone who has ever wondered how to make film on no budget should see this documentary The determination of everybody portrayed in this project was very moving to me and should connect to those of us who have ever ventured into any part of show business be it film music or writing think the film makers could have done better job with foreshadowing the events that led up to this film becoming documentary perhaps by use of narrator other than that the film comes off as real example of how show business isn about the show but rather the business hope that the actual intended project Repo Man II gets to see the light of day think the film makers did fine job on it with what little they had to work with and all that they had to overcome to complete it \n",
      "\n",
      "----------------------------------------------\n",
      "True class: Positive review\n",
      "Predicted class: Positive review ( 0.0063616955 ) [0=True, 1=False]\n",
      "\n",
      "Top 10 - Positive Contribute\n",
      "[('in', 0.0006671252), ('some', 0.0005989384), ('of', 0.00055471127), ('are', 0.00054561655), ('memorable', 0.00051731884)]\n",
      "\n",
      "Top 10 - Negative Contribute\n",
      "[('by', -0.0004163511), ('somewhere', -0.00046498099), ('background', -0.0004750903), ('noise', -0.0006024074), ('primary', -0.0009778026)]\n",
      "\n",
      "Text:\n",
      " I discovered this film after reading the book that inspired it It is not strictly biographical film it is loosely based on the facts But found it compelling and eerie exploration of evil and madness and Michel Serrault gives an unforgettable performance as Dr Petiot There are many memorable images in this movie Petiot traveling through the night like vampire his black cloak flapping behind him is almost iconic There are also several touches of expressionism Petiot crooked silhouette mounting the stairs leading from the cellar where the butchered remains of his victims await cremation reminds me of some scenes from Nosferatu But found the primary appeal of this movie to be aural The soundtrack is loaded with ominous sounds starting with the foreboding music of the opening credits accompanied by wordless wailing Petiot lives and runs his medical practice in complex with many small shops and there is persistent background noise of knives being sharpened somewhere as well as peddler playing eerie tunes on saw There are animal noises as well the concierge keeps goat unseen cats howl and later in the film we see hapless cattle being herded through an underpass The whole atmosphere is unsettling with overtones of violence and slaughter Not only animals but human voices are often heard the screams of Gestapo victims Petiot patients in his waiting room monitored by listening device just the same as the suspected collaborators after the war are monitored in their cells Even the action of the film is often arranged so that we hear the voices of the participants without seeing them when Petiot goes to see Mme Kern we hear her singing as she works her voice echoing in the theater before we ever see her And even when she does appear she is often filmed from behind her voice calling out to her husband whose voice calls out to her in conversation Disembodied voices echo in large halls and their owners when seen at all are photographed at distance so we cannot actually see them speaking This is ghost story and these are the voices of ghosts many of them Petiot future victims Yet Petiot himself is often only voice his frightening laughter echoes as he retreats from the camera throwing comments behind him or into the air to nobody In way he is as much ghost as those he murders He is always frantically busy scurrying from appointment to appointment never at rest But his activity is that of machine lifeless and imperturbable It is interesting that among all the horror and danger of occupied Paris Petiot alone is unafraid he is amused enthusiastic angry irritated contemptuous but never afraid unlike those real people he lures to their deaths It is no surprise that he boasts of his mechanical inventions including perpetual motion machine true detail from the book he did claim to have invented many machines he is sort of perpetual motion machine himself And mechanical imagery is everywhere in the film from the opening giant wheel in the movie house to Petiot bicycle with its squeaking wheels echoing the sound of sharpening knives to the Victrola he keeps winding up to play music before he makes kill Even his routine with his victims is mechanical write note to your wife let me disguise you before you leave you need vaccination Barcelona Casablanca Dakar like well oiled machine the routine is always the same just as the record is always the same Maeder the author says that it was the clockwork perfection of his crimes that weighed so heavily against Petiot at his trial His system was as smooth and efficient as Nazi concentration camp and this may be why the movie invents subplot of Petiot involvement with the French Gestapo and the occupying Nazis Unfortunately it doesn quite work as part of the story because it very hard to figure out just what Petiot is doing for the collaborators or what is going on when he ends up at their headquarters in the middle of the night Disposing of bodies Hiding stolen goods It hard to say and harder to believe it not likely the state would turn to freelancer like Petiot But it does remind us of the duality of evil people Petiot is robber and murderer but he is also devoted father and husband Just as we learned that Hitler loved dogs and that Nazis guilty of the worst war crimes could also be loving fathers and family men so we have to recognize that Petiot could commit unspeakable horrors and yet also function normally His insanity is easily camouflaged by the insanity and horror of the wartime situation in Paris when killing robbing and disappearing are happening all around nobody pays attention as Petiot tosses more corpses on the pile \n",
      "\n",
      "----------------------------------------------\n",
      "True class: Positive review\n",
      "Predicted class: Positive review ( 0.35370764 ) [0=True, 1=False]\n",
      "\n",
      "Top 10 - Positive Contribute\n",
      "[('the', 0.19707096), ('who', 0.17731878), ('to', 0.16730209), ('and', 0.15455979), ('an', 0.14012633)]\n",
      "\n",
      "Top 10 - Negative Contribute\n",
      "[('because', -0.17287265), ('no', -0.1732036), ('an', -0.17348146), ('am', -0.1747847), ('to', -0.2299424)]\n",
      "\n",
      "Text:\n",
      " This is docudrama story on the Lindy Chamberlain case and look at it impact on Australian society It especially looks at the problem of innuendo gossip and expectation when dealing with real life dramas One issue the story deals with is the way it is expected people will all give the same emotional response to similar situations Not everyone goes into wild melodramatic hysterics to every major crisis Just because the characters in the movies and on TV act in certain way is no reason to expect real people to do so This is especially apt for journalists and news editors who appear to be looking for the the big sob scene that will pull the ratings It an issue that has to be constantly addressed The leads play the characters with depth personality and sensitivity And they are ably supported by large cast all playing based on fact individuals Some viewers may be surprised to learn that many of the supporting cast in this story are people better known in Australia as comic actors It re enforces my idea that comic actors make some of the best supports in dramas because with comedy they know how to establish quick impressions of individuals Spoiler warning have to say something very personal here in that am actually an ex Adventist who was practicing member in Australia at the time this incident occurred so have slightly different impression of the story than most think it is handled with amazing creativity and personality and emotional heart think the best scene is the one where the couple are hounded by the new choppers It captured the themes of the story brilliantly once heard Fred Schepsi say in an interview that he told the actors to play the best case for their character they could While this is especially apt for this story think it is also general principle that should apply to all acting as well \n",
      "\n",
      "----------------------------------------------\n",
      "True class: Negative review\n",
      "Predicted class: Negative review ( 0.78063226 ) [0=True, 1=False]\n",
      "\n",
      "Top 10 - Positive Contribute\n",
      "[('by', 0.44791958), ('soap', 0.39699167), ('to', 0.35781989), ('slow', 0.34597626), ('out', 0.34310856)]\n",
      "\n",
      "Top 10 - Negative Contribute\n",
      "[('cheese', -0.2572629), ('time', -0.26399258), ('fun', -0.3231549), ('watching', -0.3784554), ('their', -0.419905)]\n",
      "\n",
      "Text:\n",
      " When bought this film expected to get fun exploitation film Instead got this bore fest by amateur auteur Andy Milligan Ah Andy Milligan With his tight editing breakneck pacing and wonderfully well known actors you almost think you re watching one of his home movies Seriously couldn even stay awake the first time tried to watch it The scenes of boring people dragged on an on and whenever someone got killed the film would slow down Sometimes it would speed up too making the characters voices sound like chipmunks which was probably the best thing about this film The script actually seemed bit better than the film and seems more well suited to be in soap opera than in grainy sleeping pill where the actors constantly stumble over it lines The cover said Their prime cuts were curiously erotic but thoroughly brutal Trust me there is nothing erotic about this film Oh we do get to see characters that resemble extra lumpy cottage cheese making out but that about it And as far as brutal well the viewer is brutalized the most with this here film And another thing \n",
      "\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in random_cases:\n",
    "    find_top(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Insights</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LRP method is suitable for making a trust in the model individual prediction. But it lacks method to build trust in the model. As can be seen from LRP results: \n",
    "1. Despite being model accuracy being 91%, it seems the current model lacks in learning the important words for classifying the text.\n",
    "2. It highlights the need to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
